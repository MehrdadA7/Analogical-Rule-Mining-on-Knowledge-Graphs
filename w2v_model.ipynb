{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-w2v\" data-toc-modified-id=\"Load-w2v-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load w2v</a></span></li><li><span><a href=\"#Read-entity2id.txt-and-create-the-similarity-data-frame.\" data-toc-modified-id=\"Read-entity2id.txt-and-create-the-similarity-data-frame.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Read entity2id.txt and create the similarity data frame.</a></span></li><li><span><a href=\"#Append-the-similarity-links\" data-toc-modified-id=\"Append-the-similarity-links-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Append the similarity links</a></span></li><li><span><a href=\"#Apply-AMIE-and-Evaluate\" data-toc-modified-id=\"Apply-AMIE-and-Evaluate-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Apply AMIE and Evaluate</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This is the model from https://code.google.com/archive/p/word2vec/.  \n",
    "You can find it under __Pre-trained entity vectors with Freebase naming__, with the following name/link:  \n",
    "[freebase-vectors-skipgram1000.bin.gz](https://docs.google.com/file/d/0B7XkCwpI5KDYaDBDQm1tZGNDRHc/edit?usp=sharing)\n",
    "\n",
    "Download the bin file and and put it in a folder named __`w2v_data`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load w2v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:16:57.721703Z",
     "start_time": "2020-05-13T19:16:57.716314Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.models as w2v       # Word2Vec Library\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "from shutil import copyfile\n",
    "\n",
    "W2V_THR = .85 # Threshold for Cosine similarity of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:37:49.639611Z",
     "start_time": "2020-05-13T17:36:54.410696Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_w2v = w2v.KeyedVectors.load_word2vec_format('./w2v_data/freebase-vectors-skipgram1000.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:47:12.591294Z",
     "start_time": "2020-05-13T17:47:12.577633Z"
    }
   },
   "outputs": [],
   "source": [
    "all_voc = wiki_w2v.index2entity # List of all words in w2v. They are in /mid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:14:11.290735Z",
     "start_time": "2020-05-13T19:14:11.284837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 1422903\n",
      "example: /m/0dgps15\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words: \" + str(len(all_voc)))\n",
    "print(\"example: \" + all_voc[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read entity2id.txt and create the similarity data frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read \"/OpenKE/benchmarks/FB15K/entity2id.txt\" into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:48:50.289050Z",
     "start_time": "2020-05-13T17:48:50.202329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all the entities in FB15K\n",
    "ents = pd.read_csv(\"./OpenKE/benchmarks/FB15K/entity2id.txt\",\n",
    "                   sep = '\\t',header=None, names=['mid'], \n",
    "                   skiprows=[0],usecols=[0]) # first row is total line\n",
    "\n",
    "ents_list = list(ents['mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:08:25.450639Z",
     "start_time": "2020-05-13T18:05:32.538636Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the intersection of w2v and FB15K\n",
    "new_list = []\n",
    "for w in ents_list:\n",
    "    if w in all_voc:\n",
    "        new_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:16:06.037878Z",
     "start_time": "2020-05-13T19:16:06.030951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13910\n"
     ]
    }
   ],
   "source": [
    "tot = len(new_list) # number of FB15K words that are also in w2v.\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:18:45.304380Z",
     "start_time": "2020-05-13T19:17:10.056465Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9f2fdbb8aadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mwiki_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mW2V_THR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \"\"\"\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate the similarities and filter by W2V_THR\n",
    "h = []\n",
    "t = []\n",
    "\n",
    "for i,j in combinations(range(tot),2):\n",
    "    w1 = new_list[i]\n",
    "    w2 = new_list[j]\n",
    "    if wiki_w2v.similarity(w1,w2) > W2V_THR:\n",
    "        h.append(w1)\n",
    "        t.append(w2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:18:49.285232Z",
     "start_time": "2020-05-13T19:18:49.279052Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'head':h , 'tail':t}\n",
    "w2v_df = pd.DataFrame(data=d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:18:51.969037Z",
     "start_time": "2020-05-13T19:18:51.954470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/01cwm1</td>\n",
       "      <td>/m/02029f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/01cwm1</td>\n",
       "      <td>/m/01n7rc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/019v9k</td>\n",
       "      <td>/m/016t_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/071wvh</td>\n",
       "      <td>/m/02qvhbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/071wvh</td>\n",
       "      <td>/m/02ql_ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/m/071wvh</td>\n",
       "      <td>/m/047s_cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/m/071wvh</td>\n",
       "      <td>/m/02qnyr7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/m/0f0y8</td>\n",
       "      <td>/m/053yx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/m/0f0y8</td>\n",
       "      <td>/m/0lgm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/m/027nb</td>\n",
       "      <td>/m/06s0l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/m/01453</td>\n",
       "      <td>/m/075q_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/m/01453</td>\n",
       "      <td>/m/045xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/m/01453</td>\n",
       "      <td>/m/02rjz5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/m/01453</td>\n",
       "      <td>/m/0138mv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/m/01453</td>\n",
       "      <td>/m/04999m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/m/02b15h</td>\n",
       "      <td>/m/01dtl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/m/02b15h</td>\n",
       "      <td>/m/01x4wq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/m/02b15h</td>\n",
       "      <td>/m/0182r9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/m/02b15h</td>\n",
       "      <td>/m/02b185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/01j95f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/02gjt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/02b0y3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/015_z1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/01yxbw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/027024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/02b10g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/01_8n9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/02b1l_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/02b10w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/0jv5x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/m/01j_jh</td>\n",
       "      <td>/m/02b14q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>/m/0hd7j</td>\n",
       "      <td>/m/01dzg0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         head        tail\n",
       "0   /m/01cwm1   /m/02029f\n",
       "1   /m/01cwm1   /m/01n7rc\n",
       "2   /m/019v9k   /m/016t_3\n",
       "3   /m/071wvh  /m/02qvhbb\n",
       "4   /m/071wvh  /m/02ql_ms\n",
       "5   /m/071wvh  /m/047s_cr\n",
       "6   /m/071wvh  /m/02qnyr7\n",
       "7    /m/0f0y8    /m/053yx\n",
       "8    /m/0f0y8    /m/0lgm5\n",
       "9    /m/027nb    /m/06s0l\n",
       "10   /m/01453    /m/075q_\n",
       "11   /m/01453    /m/045xx\n",
       "12   /m/01453   /m/02rjz5\n",
       "13   /m/01453   /m/0138mv\n",
       "14   /m/01453   /m/04999m\n",
       "15  /m/02b15h    /m/01dtl\n",
       "16  /m/02b15h   /m/01x4wq\n",
       "17  /m/02b15h   /m/0182r9\n",
       "18  /m/02b15h   /m/02b185\n",
       "19  /m/01j_jh   /m/01j95f\n",
       "20  /m/01j_jh   /m/02gjt4\n",
       "21  /m/01j_jh   /m/02b0y3\n",
       "22  /m/01j_jh   /m/015_z1\n",
       "23  /m/01j_jh   /m/01yxbw\n",
       "24  /m/01j_jh   /m/027024\n",
       "25  /m/01j_jh   /m/02b10g\n",
       "26  /m/01j_jh   /m/01_8n9\n",
       "27  /m/01j_jh   /m/02b1l_\n",
       "28  /m/01j_jh   /m/02b10w\n",
       "29  /m/01j_jh    /m/0jv5x\n",
       "30  /m/01j_jh   /m/02b14q\n",
       "31   /m/0hd7j   /m/01dzg0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append the similarity links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:26:35.823231Z",
     "start_time": "2020-05-13T19:26:35.813455Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_train(input_df,new_name):\n",
    "    \"\"\" Appends the input data frame to a copy of train.txt.\n",
    "    \n",
    "    input_df: --pd.DataFrame: has two columns 'head', and 'tail' containing\n",
    "    the integer ids for heads and tails of similar tuples.\n",
    "    new_name: --str: name of the new file will be train_{new_name}.txt \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import datetime\n",
    "    new_name = new_name + str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    dest = './FB15K/train_'+ new_name + '.txt'\n",
    "    while os.path.isfile(dest):\n",
    "        new_name = input(\"File already exists. Give another name: \")\n",
    "        dest = './FB15K/train_'+ new_name + '.txt'\n",
    "    \n",
    "    heads = list(input_df['head']) \n",
    "    tails = list(input_df['tail']) \n",
    "    rels_mid = ['/similar_to']*len(heads)\n",
    "\n",
    "\n",
    "    d = {'head': heads , 'relation': rels_mid, 'tail':tails}\n",
    "    df = pd.DataFrame(data=d)\n",
    "\n",
    "    from shutil import copyfile\n",
    "    copyfile('./FB15K/train.txt', dest)\n",
    "    df.to_csv(dest, mode='a', header=False,index=False, sep='\\t')\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:26:37.962527Z",
     "start_time": "2020-05-13T19:26:37.923797Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sub = append_train(w2v_df, 'w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:26:39.354869Z",
     "start_time": "2020-05-13T19:26:39.348612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./FB15K/train_w2v2020-05-13_15-26-37.txt'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply AMIE and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:26:41.732334Z",
     "start_time": "2020-05-13T19:26:41.719559Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_amie_output(path):\n",
    "    \"\"\"\n",
    "    Warning: this function overwrites the file in path\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        f_contents = f.readlines()\n",
    "        \n",
    "    f_contents = f_contents[13:-3]\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        f.writelines(f_contents)\n",
    "        \n",
    "    print('Rules at %s file cleaned.' % path)\n",
    "    \n",
    "def eval_frame(file, test_len):\n",
    "    \n",
    "    # Open file\n",
    "    f = open(file)\n",
    "    \n",
    "    # Hits counter\n",
    "    hits = 0\n",
    "    \n",
    "    # Loop though all facts in KB\n",
    "    for x in range(test_len):\n",
    "\n",
    "        # Read line\n",
    "        fact = f.readline()\n",
    "        fact = fact.split(' ')\n",
    "        if fact != ['']:\n",
    "            # Get target head and tail\n",
    "            head_target = fact[0]\n",
    "            tail_target = fact[2][:-1]\n",
    "\n",
    "\n",
    "            # Get head predictions\n",
    "            headpreds = f.readline()\n",
    "            headpreds = headpreds.split(' ')\n",
    "            headpreds = headpreds[1].split('\\t')\n",
    "            headpreds.pop()\n",
    "\n",
    "            # Get tail predictions\n",
    "            tailpreds = f.readline()\n",
    "            tailpreds = tailpreds.split(' ')\n",
    "            tailpreds = tailpreds[1].split('\\t')\n",
    "            tailpreds.pop()\n",
    "\n",
    "\n",
    "            if (head_target in headpreds) and (tail_target in tailpreds):\n",
    "                if (len(headpreds) < 10) and (len(tailpreds) < 10):\n",
    "                    hits+=1\n",
    "        else:\n",
    "            print('miss')\n",
    "                \n",
    "    return hits/(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:26:44.885997Z",
     "start_time": "2020-05-13T19:26:44.879123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_w2v2020-05-13_15-26-37.txt'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = train_sub\n",
    "name[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T19:27:25.791168Z",
     "start_time": "2020-05-13T19:26:47.599768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The enriched tr file: FB15k/train_w2v2020-05-13_15-26-37.txt\n",
      "Rules will be saved at: rules/Enriched_rules_w2v2020-05-13_15-26-37.txt\n",
      "And rule evaluations at: evaluation/Enriched_eval_w2v2020-05-13_15-26-37.txt\n",
      "\n",
      " AMIE_plus output: 33280\n",
      "Rules at rules/Enriched_rules_w2v2020-05-13_15-26-37.txt file cleaned.\n",
      "\n",
      " Apply_AMIE_Rules output: 0\n",
      "\n",
      " Hits@10: 0.12390174535728192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_add = \"FB15K/train\" +  name[13:] # From append module\n",
    "rules_add = \"rules/Enriched_rules\" + name[13:] # modify this name if you like\n",
    "eval_add = \"evaluation/Enriched_eval\" + name[13:] # same here\n",
    "\n",
    "test_add = \"FB15K/test.txt\"\n",
    "valid_add = \"FB15K/valid.txt\"\n",
    "\n",
    "import subprocess\n",
    "test_len = subprocess.run(['wc', '-l', test_add], \n",
    "                          stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "test_len = int(test_len.split()[0])\n",
    "test_len\n",
    "\n",
    "print(\"The enriched tr file: \" + train_add)\n",
    "print(\"Rules will be saved at: \"+ rules_add)\n",
    "print(\"And rule evaluations at: \" + eval_add)\n",
    "\n",
    "# The texts of the commands for running AMIE\n",
    "AMIE_plus = (\"java -XX:-UseGCOverheadLimit -Xmx4g -jar AMIE/amie_plus.jar \"\n",
    "\"-minhc 0.0 -mins 0 -minis 0 \" \n",
    "f\"{train_add} > {rules_add}\")\n",
    "\n",
    "Apply_AMIE_RULES = (f'java -jar AMIE/ApplyAMIERules.jar {rules_add}' \n",
    "                    f' {train_add} {test_add} {valid_add}'\n",
    "                    f' {eval_add}')\n",
    "\n",
    "x = os.system(AMIE_plus)\n",
    "print(\"\\n AMIE_plus output: \" + str(x))\n",
    "    \n",
    "# trim `Enriched_rules{}.txt` again\n",
    "clean_amie_output(rules_add)\n",
    "\n",
    "y = os.system(Apply_AMIE_RULES) # if output is 256 then you forgot to trim\n",
    "print(\"\\n Apply_AMIE_Rules output: \" + str(y))\n",
    "    \n",
    "print('\\n Hits@10: ' + str(eval_frame(eval_add, test_len)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.8px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
